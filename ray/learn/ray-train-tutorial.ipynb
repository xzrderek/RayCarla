{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray Train Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import ray.train as train\n",
    "from ray.train import Trainer, TorchConfig\n",
    "from ray.train.callbacks import JsonLoggerCallback, TBXLoggerCallback\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from torch.utils.data import DistributedSampler\n",
    "\n",
    "\n",
    "class LinearDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"y = a * x + b\"\"\"\n",
    "\n",
    "    def __init__(self, a, b, size=1000):\n",
    "        x = np.arange(0, 10, 10 / size, dtype=np.float32)\n",
    "        self.x = torch.from_numpy(x)\n",
    "        self.y = torch.from_numpy(a * x + b)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index, None], self.y[index, None]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "\n",
    "def train_epoch(dataloader, model, loss_fn, optimizer):\n",
    "    for X, y in dataloader:\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def validate_epoch(dataloader, model, loss_fn):\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            loss += loss_fn(pred, y).item()\n",
    "    loss /= num_batches\n",
    "    result = {\"model\": model.state_dict(), \"loss\": loss}\n",
    "    return result\n",
    "\n",
    "\n",
    "def train_func(config):\n",
    "    data_size = config.get(\"data_size\", 1000)\n",
    "    val_size = config.get(\"val_size\", 400)\n",
    "    batch_size = config.get(\"batch_size\", 32)\n",
    "    hidden_size = config.get(\"hidden_size\", 1)\n",
    "    lr = config.get(\"lr\", 1e-2)\n",
    "    epochs = config.get(\"epochs\", 3)\n",
    "\n",
    "    train_dataset = LinearDataset(2, 5, size=data_size)\n",
    "    val_dataset = LinearDataset(2, 5, size=val_size)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        sampler=DistributedSampler(train_dataset))\n",
    "    validation_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        sampler=DistributedSampler(val_dataset))\n",
    "\n",
    "    model = nn.Linear(1, hidden_size)\n",
    "    model = DistributedDataParallel(model)\n",
    "\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        train_epoch(train_loader, model, loss_fn, optimizer)\n",
    "        result = validate_epoch(validation_loader, model, loss_fn)\n",
    "        train.report(**result)\n",
    "        results.append(result)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def train_linear(num_workers=2):\n",
    "    trainer = Trainer(TorchConfig(backend=\"gloo\"), num_workers=num_workers)\n",
    "    config = {\"lr\": 1e-2, \"hidden_size\": 1, \"batch_size\": 4, \"epochs\": 3}\n",
    "    trainer.start()\n",
    "    results = trainer.run(\n",
    "        train_func,\n",
    "        config,\n",
    "        callbacks=[JsonLoggerCallback(),\n",
    "                   TBXLoggerCallback()])\n",
    "    trainer.shutdown()\n",
    "\n",
    "    print(results)\n",
    "    return results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--address\",\n",
    "        required=False,\n",
    "        type=str,\n",
    "        help=\"the address to use for Ray\")\n",
    "    parser.add_argument(\n",
    "        \"--num-workers\",\n",
    "        \"-n\",\n",
    "        type=int,\n",
    "        default=2,\n",
    "        help=\"Sets number of workers for training.\")\n",
    "    parser.add_argument(\n",
    "        \"--smoke-test\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "        help=\"Finish quickly for testing.\")\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    import ray\n",
    "\n",
    "    if args.smoke_test:\n",
    "        ray.init(num_cpus=2)\n",
    "    else:\n",
    "        ray.init(address=args.address)\n",
    "\n",
    "    train_linear(num_workers=args.num_workers)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0c060b2a3575904847ee0539dc2ac171628bacad6a3b01483d90c97ee6179c16"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('venv-3.7': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
