{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References \n",
    "- [Ray Train](https://docs.ray.io/en/latest/train/train.html#)\n",
    "- [Tensorboard & Pytorch](https://pytorch.org/docs/stable/tensorboard.html)\n",
    "\n",
    "First, set up your dataset and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "num_samples = 20\n",
    "input_size = 10\n",
    "layer_size = 15\n",
    "output_size = 5\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, layer_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(layer_size, output_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.layer2(self.relu(self.layer1(input)))\n",
    "\n",
    "# In this example we use a randomly generated dataset.\n",
    "input = torch.randn(num_samples, input_size)\n",
    "labels = torch.randn(num_samples, output_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define your single-worker PyTorch training function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# Writer will output to ./runs/ directory by default\n",
    "writer = SummaryWriter()\n",
    "\n",
    "\n",
    "def train_func():\n",
    "    num_epochs = 30\n",
    "    \n",
    "    ckpt_dir = \"ckpts\"\n",
    "    os.makedirs(ckpt_dir, exist_ok=True)\n",
    "\n",
    "    model = NeuralNetwork()\n",
    "    writer.add_graph(model, input) # Add graph to tensorboard, default goto ./runs\n",
    "\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        output = model(input) # x1 = A x0\n",
    "        loss = loss_fn(output, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        writer.add_scalar('Loss/train', loss.item(), epoch) # Add loss to tensorboard\n",
    "        \n",
    "        # Checkpoint model\n",
    "        ckpt_path = os.path.join(ckpt_dir, \"model-{}.pt\".format(epoch))\n",
    "        torch.save(model.state_dict(), ckpt_path)\n",
    "        \n",
    "        print(f\"epoch: {epoch}, loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This training function can be executed with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 1.2137645483016968\n",
      "epoch: 1, loss: 1.1585373878479004\n",
      "epoch: 2, loss: 1.1137664318084717\n",
      "epoch: 3, loss: 1.0762763023376465\n",
      "epoch: 4, loss: 1.0443921089172363\n",
      "epoch: 5, loss: 1.0168265104293823\n",
      "epoch: 6, loss: 0.9926542639732361\n",
      "epoch: 7, loss: 0.9713320136070251\n",
      "epoch: 8, loss: 0.952486515045166\n",
      "epoch: 9, loss: 0.9356498122215271\n",
      "epoch: 10, loss: 0.9199298024177551\n",
      "epoch: 11, loss: 0.9052792191505432\n",
      "epoch: 12, loss: 0.8915045857429504\n",
      "epoch: 13, loss: 0.878430187702179\n",
      "epoch: 14, loss: 0.8659675121307373\n",
      "epoch: 15, loss: 0.8541174530982971\n",
      "epoch: 16, loss: 0.8426482677459717\n",
      "epoch: 17, loss: 0.8315061330795288\n",
      "epoch: 18, loss: 0.8206733465194702\n",
      "epoch: 19, loss: 0.810304582118988\n",
      "epoch: 20, loss: 0.8003292679786682\n",
      "epoch: 21, loss: 0.7905774712562561\n",
      "epoch: 22, loss: 0.7809650301933289\n",
      "epoch: 23, loss: 0.7715209126472473\n",
      "epoch: 24, loss: 0.7621709704399109\n",
      "epoch: 25, loss: 0.7529958486557007\n",
      "epoch: 26, loss: 0.7437600493431091\n",
      "epoch: 27, loss: 0.7343636155128479\n",
      "epoch: 28, loss: 0.7250633835792542\n",
      "epoch: 29, loss: 0.7158535122871399\n"
     ]
    }
   ],
   "source": [
    "train_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open tensorboard to check loss and network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "I1123 01:27:46.953557 140317629609728 plugin.py:346] Monitor runs begin\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.7.0 at http://localhost:6007/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "! tensorboard --logdir=runs"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65cdd5b4a0e89948390188008d4fb68a6c5e0d3e09a99d6a4df67b3be73eed40"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('3.7': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
