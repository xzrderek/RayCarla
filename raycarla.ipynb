{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup\n",
    "First enter into virtualenv. Do below in terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# virtualenv venv\n",
    "# source venv/bin/activate\n",
    "# pip install -r requirements.txt\n",
    "# python -m easy_install carla-0.9.6-py3.5-linux-x86_64.egg\n",
    "\n",
    "# Select venv/bin/python in vscode\n",
    "\n",
    "# Change ipython kernel to venv/bin/python when prompted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then setup PYTHONPATH as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('.'))\n",
    "import oatomobile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "## Option 1: Download Datset from OATML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oatomobile.datasets import CARLADataset\n",
    "output_dir = \"data-oatml\"\n",
    "dataset = CARLADataset(\"raw\")\n",
    "dataset.download_and_prepare(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oatomobile.datasets import CARLADataset\n",
    "output_dir = \"data-oatml\"\n",
    "dataset = CARLADataset(\"examples\")\n",
    "dataset.download_and_prepare(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oatomobile.datasets import CARLADataset\n",
    "output_dir = \"data-oatml\"\n",
    "dataset = CARLADataset(\"processed\")\n",
    "dataset.download_and_prepare(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: Collect from Carla\n",
    "To confirm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oatomobile.datasets import CARLADataset\n",
    "town = \"Town01\" # Options: Town01, Town02, Town03, Town04, Town05\n",
    "town2 = \"Town02\" # for validation examples?\n",
    "raw_dir = \"data/raw\" \n",
    "processed_dir = \"data/processed\" \n",
    "examples_dir = \"data/examples\" \n",
    "vehicles = 10\n",
    "pedestrians = 10\n",
    "render = True\n",
    "dataset = CARLADataset(\"raw\")\n",
    "dataset.collect(town=town, output_dir=raw_dir, num_vehicles=vehicles, \n",
    "    num_pedestrians=pedestrians, render=render)\n",
    "dataset.process(dataset_dir=raw_dir, output_dir=processed_dir)\n",
    "# Not sure what examples are yet\n",
    "dataset.collect(town=town2, output_dir=examples_dir, num_vehicles=vehicles, \n",
    "    num_pedestrians=pedestrians, render=render, num_steps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "The options are dim and cil. \n",
    "\n",
    "## Train the dim Imitative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!PYTHONPATH=\".\" python oatomobile/baselines/torch/dim/train.py \\\n",
    "    --dataset_dir=data-oatml/processed \\\n",
    "    --output_dir=data-oatml/model-dim \\\n",
    "    --num_epochs=50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the cil Behavioural Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!PYTHONPATH=\".\" python oatomobile/baselines/torch/cil/train.py \\\n",
    "    --dataset_dir=data/dataset \\\n",
    "    --output_dir=data/model/cil \\\n",
    "    --num_epochs=50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "Let's drive (inferernce)!\n",
    "\n",
    "## Inference from dim imitative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imitation-learners.\n",
    "import torch\n",
    "import oatomobile.baselines.torch\n",
    "import oatomobile\n",
    "from oatomobile.envs import CARLAEnv\n",
    "\n",
    "ckpt = \"data-oatml/model/dim/ckpts/model-640.pt\"\n",
    "town = \"Town02\"\n",
    "\n",
    "model = oatomobile.baselines.torch.ImitativeModel()\n",
    "model.load_state_dict(torch.load(ckpt))\n",
    "\n",
    "# Initializes a CARLA environment.\n",
    "environment = CARLAEnv(town=town)\n",
    "# Makes an initial observation.\n",
    "observation = environment.reset()\n",
    "done = False\n",
    "\n",
    "agent = oatomobile.baselines.torch.DIMAgent(\n",
    "  environment=environment,\n",
    "  model=model,\n",
    "  )\n",
    "\n",
    "while not done:\n",
    "  action = agent.act(observation)\n",
    "  observation, reward, done, info = environment.step(action)\n",
    "  # Renders interactive display.\n",
    "  environment.render(mode=\"human\")\n",
    "\n",
    "# # Book-keeping: closes\n",
    "environment.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference from cil bahivior model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imitation-learners.\n",
    "import torch\n",
    "import oatomobile.baselines.torch\n",
    "import oatomobile\n",
    "from oatomobile.envs import CARLAEnv\n",
    "\n",
    "town = \"Town02\"\n",
    "ckpt = \"data-oatml/model/dim/ckpts/model-600.pt\" # Paths to the model checkpoints.\n",
    "\n",
    "model = oatomobile.baselines.torch.ImitativeModel()\n",
    "model.load_state_dict(torch.load(ckpt))\n",
    "\n",
    "# Initializes a CARLA environment.\n",
    "environment = CARLAEnv(town=town)\n",
    "# Makes an initial observation.\n",
    "observation = environment.reset()\n",
    "done = False\n",
    "\n",
    "agent = oatomobile.baselines.torch.CILAgent(\n",
    "  environment=environment,\n",
    "  model=model\n",
    "  )\n",
    "\n",
    "while not done:\n",
    "  action = agent.act(observation)\n",
    "  observation, reward, done, info = environment.step(action)\n",
    "  # Renders interactive display.\n",
    "  environment.render(mode=\"human\")\n",
    "\n",
    "# # Book-keeping: closes\n",
    "environment.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference from rip ensemble model\n",
    "\n",
    "Can we handle out of distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imitation-learners.\n",
    "import torch\n",
    "import oatomobile.baselines.torch\n",
    "import oatomobile\n",
    "from oatomobile.envs import CARLAEnv\n",
    "\n",
    "town = \"Town02\"\n",
    "ckpts = [ \\\n",
    "  \"data-oatml/model/dim/ckpts/model-100.pt\",\n",
    "  \"data-oatml/model/dim/ckpts/model-200.pt\",\n",
    "  \"data-oatml/model/dim/ckpts/model-300.pt\",\n",
    "  \"data-oatml/model/dim/ckpts/model-400.pt\", \n",
    "  ] # Paths to the model checkpoints.\n",
    "models = [oatomobile.baselines.torch.ImitativeModel() for _ in range(4)]\n",
    "\n",
    "for model, ckpt in zip(models, ckpts):\n",
    "  model.load_state_dict(torch.load(ckpt))\n",
    "\n",
    "# Initializes a CARLA environment.\n",
    "environment = CARLAEnv(town=town)\n",
    "# Makes an initial observation.\n",
    "observation = environment.reset()\n",
    "done = False\n",
    "\n",
    "agent = oatomobile.baselines.torch.RIPAgent(\n",
    "  environment=environment,\n",
    "  models=models,\n",
    "  algorithm=\"WCM\",\n",
    "  )\n",
    "\n",
    "while not done:\n",
    "  action = agent.act(observation)\n",
    "  observation, reward, done, info = environment.step(action)\n",
    "  # Renders interactive display.\n",
    "  environment.render(mode=\"human\")\n",
    "\n",
    "# # Book-keeping: closes\n",
    "environment.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "Open tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir data/model/dim/logs/"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "32629b6d8bb3447e3095207018032b9b40e345d6412b0cdb2d1e92c294cb2497"
  },
  "kernelspec": {
   "display_name": "Python 3.5.10 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
